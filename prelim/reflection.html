<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Laboratory Exercises</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet"/>
  <style>
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
      font-family: 'Inter', sans-serif;
    }

    body {
      background: #f9fafb;
      color: #1e293b;
      padding: 2rem;
    }

    header {
      text-align: center;
      margin-bottom: 2rem;
    }

    h1 {
      font-size: 2rem;
      color: #0f172a;
    }

    nav {
      display: flex;
      justify-content: space-between;
      margin-bottom: 1.5rem;
    }

    .nav-button {
      background-color: #38bdf8;
      color: white;
      padding: 0.5rem 1rem;
      border: none;
      border-radius: 6px;
      text-decoration: none;
      font-weight: 600;
      transition: background-color 0.3s;
    }

    .nav-button:hover {
      background-color: #0ea5e9;
    }

    .back-button {
      background-color: #1f2937; /* Dark gray */
      color: #f8fafc; /* Almost white */
      padding: 0.5rem 1.25rem;
      border: 1px solid #374151; /* Slight border */
      border-radius: 8px;
      font-weight: 600;
      font-size: 0.95rem;
      text-decoration: none;
      transition: background-color 0.3s, transform 0.2s ease;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.15);
    }

    .back-button:hover {
      background-color: #111827; /* Almost black */
      transform: translateY(-1px);
    }


    .gallery {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
      gap: 1.5rem;
      justify-content: center;
    }

    .gallery-item {
      background-color: white;
      border-radius: 8px;
      box-shadow: 0 4px 8px rgba(0,0,0,0.08);
      overflow: hidden;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 1rem;
      transition: transform 0.2s;
      cursor: pointer;
    }

    .gallery-item img {
      max-width: 100%;
      height: auto;
      border-radius: 6px;
      object-fit: cover;
      transition: transform 0.2s ease;
    }

    .gallery-item figcaption {
      margin-top: 0.5rem;
      font-size: 0.9rem;
      color: #475569;
      text-align: center;
    }

    .gallery-item:hover img {
      transform: scale(1.02);
    }

    .reflection {
      margin-top: 3rem;
      padding: 1.5rem;
      background-color: #f1f5f9;
      border-left: 4px solid #38bdf8;
      border-radius: 8px;
    }

    .reflection h2 {
      margin-bottom: 1rem;
      font-size: 1.2rem;
      color: #0c4a6e;
    }

    .reflection p {
      line-height: 1.6;
    }

    .lightbox {
      display: none;
      position: fixed;
      z-index: 1000;
      left: 0;
      top: 0;
      width: 100vw;
      height: 100vh;
      background-color: rgba(0, 0, 0, 0.85);
      justify-content: center;
      align-items: center;
      flex-direction: column;
      color: white;
      padding: 2rem;
    }

    .lightbox:target {
      display: flex;
    }

    .lightbox-content {
      display: flex;
      max-width: 90%;
      height: 80vh;
      background-color: #1e293b;
      border-radius: 8px;
      overflow: hidden;
      box-shadow: 0 0 30px rgba(0,0,0,0.4);
    }

    .lightbox-img {
      width: 60%;
      height: 100%;
      object-fit: contain;
      background-color: black;
    }

    .lightbox-comments {
      width: 40%;
      background-color: #0f172a;
      display: flex;
      flex-direction: column;
      overflow-y: auto;
      max-height: 100%;
      border-left: 1px solid #334155;
      padding: 1rem;
      gap: 1rem;
    }

    .lightbox-comments h3 {
      font-size: 1rem;
      margin-bottom: 0.5rem;
      color: #f1f5f9;
    }

    .comment-block {
      background-color: #1e293b;
      padding: 0.75rem;
      border-radius: 6px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    .comment-block strong {
      display: block;
      margin-bottom: 0.35rem;
      color: #38bdf8;
    }

    .comment-block p {
      font-size: 0.9rem;
      color: #cbd5e1;
      line-height: 1.6;
      white-space: pre-wrap;
      word-break: break-word;
    }

    .lightbox-instruction {
      margin-top: 1rem;
      font-size: 0.9rem;
      color: #cbd5e1;
      text-align: center;
    }

    @media (max-width: 768px) {
      .lightbox-content {
        flex-direction: column;
      }

      .lightbox-img {
        width: 100%;
        height: 50vh;
      }

      .lightbox-comments {
        width: 100%;
        height: 50vh;
      }
    }

    footer {
      margin-top: 4rem;
      text-align: center;
      font-size: 0.85rem;
      color: #94a3b8;
    }
  </style>
</head>
<body>
  <nav>
    <a href="../index.htm" class="back-button">&larr; </a>
  </nav>

  <header>
      <h1 style="margin-bottom: 1rem;">My Reflection throughout the Prelims</h1>
  </header>

  <div class="reflection" id="reflection">
    <h2>Learning Reflection</h2>
    <p>
      Understanding Named Entity Recognition or NER builds the foundation for advanced NLP tasks because NER, at its core concept,
is the ability to provide the machine an initial form of context-awareness for the sentences or dataset that will be used for
sentiment analysis, text extraction or other NLP technologies for the reason at hand lies in the inability of Text-Representation
Methods such as TF-IDF, Bag of words, etc cannot provide context-awareness or some semblance of it during the preprocessing stage.

The preprocessing pipeline is where raw text is turned into stable, reliable inputs for models. Steps typically include cleaning (removing or normalizing punctuation/or slangs, URLs), tokenization (splitting text into tokens/words), normalization (lowercasing), and stopword removal to reduce unnecessary data that may affect the overall output of the model because it may provide undesired results because it got lost in the context of unecessary words. Each step reduces noise and helps models learn real patterns faster and more robustly.

Working with a small dataset like we have done in the prelims is a good controlled environment to learn effects of each preprocessing step. It lets you inspect intermediate outputs (tokenizations, vectorization, stopword removals etc.) and measure how each change affects model behavior before scaling to larger data

Bag-of-Words creates a vocabulary of tokens and represents documents as counts of those tokens, producing high-dimensional, sparse vectors. However, it must be noted that BoW counts frequencies but does not preserve word order or syntactic position — it’s a “bag” not “sequence" that can locate positions unlike dictionary lookup.

Bag of words suffers from memory problems because of its design of vectors and this is where tf-idf comes in because it improves on pure counts by down-weighting very common words (high document frequency) and up-weighting terms that are "less-used" across documents. That helps models that will be implemented on later topics to focus on informative features.

Removing stopwords (for example common words like “the”, “is”, “and”) is often a necessary precursor for BoW/TF-IDF because those words add many features that carry little information or context within the sentence that turns it unnecessary or excess words. Excess and irrelevant features increase processing time, enlarge memory usage, and can degrade the overall model performance.
    </p>
  </div>

  <footer>
    &copy; 2025 S. R. | BSIT Academic E-Portfolio
  </footer>
</body>
</html>
